{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = tf.image.resize(image, image_size)  # Resize image\n",
    "    image = (image - 127.5) / 127.5  # Normalize to [-1, 1]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(folder_path, batch_size, image_size=(64, 64)):\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        folder_path,\n",
    "        label_mode=None,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    dataset = dataset.map(preprocess_image)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (64, 64)\n",
    "batch_size = 32\n",
    "latent_dim = 100\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63565 files belonging to 1 classes.\n",
      "Dataset loaded with batch size 32 and image size (64, 64)\n"
     ]
    }
   ],
   "source": [
    "image_folder = 'images'  \n",
    "dataset = load_dataset(image_folder, batch_size)\n",
    "print(f\"Dataset loaded with batch size {batch_size} and image size {image_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim):\n",
    "    model = Sequential([\n",
    "        Dense(8*8*256, input_dim=latent_dim),\n",
    "        Reshape((8, 8, 256)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(0.2),\n",
    "        \n",
    "        Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(0.2),\n",
    "\n",
    "        Conv2DTranspose(64, (4,4), strides=(2,2), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(0.2),\n",
    "\n",
    "        Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', activation='tanh')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_discriminator(input_shape=(64, 64, 3)):\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (4,4), strides=(2,2), padding='same', input_shape=input_shape),\n",
    "        LeakyReLU(0.2),\n",
    "\n",
    "        Conv2D(128, (4,4), strides=(2,2), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(0.2),\n",
    "\n",
    "        Conv2D(256, (4,4), strides=(2,2), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(0.2),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential([generator, discriminator])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator(latent_dim)\n",
    "discriminator = build_discriminator()\n",
    "gan = build_gan(generator, discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "gan.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Calculate total images and batches per epoch\n",
    "total_images = tf.data.experimental.cardinality(dataset).numpy() * batch_size\n",
    "total_steps_per_epoch = total_images // batch_size\n",
    "\n",
    "# Training function with structured print statements for each epoch and step\n",
    "def train_gan(gan, generator, discriminator, dataset, latent_dim, epochs=1000, batch_size=32, log_interval=100):\n",
    "    d_loss_real, d_loss_fake, g_loss = [], [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        d_loss_real_epoch, d_loss_fake_epoch, g_loss_epoch = [], [], []\n",
    "        step = 0\n",
    "        \n",
    "        for real_images in dataset:\n",
    "            step += 1\n",
    "            half_batch = batch_size // 2\n",
    "\n",
    "            # Train Discriminator on Real Data\n",
    "            real_labels = tf.ones((real_images.shape[0], 1))\n",
    "            d_loss_real_batch = discriminator.train_on_batch(real_images, real_labels)\n",
    "            if isinstance(d_loss_real_batch, list):  # if it returns a list, take the first element\n",
    "                d_loss_real_batch = d_loss_real_batch[0]\n",
    "            d_loss_real_epoch.append(d_loss_real_batch)\n",
    "\n",
    "            # Train Discriminator on Fake Data\n",
    "            noise = np.random.normal(0, 1, (half_batch, latent_dim))\n",
    "            fake_images = generator.predict(noise, verbose=0)\n",
    "            fake_labels = tf.zeros((half_batch, 1))\n",
    "            d_loss_fake_batch = discriminator.train_on_batch(fake_images, fake_labels)\n",
    "            if isinstance(d_loss_fake_batch, list):  # if it returns a list, take the first element\n",
    "                d_loss_fake_batch = d_loss_fake_batch[0]\n",
    "            d_loss_fake_epoch.append(d_loss_fake_batch)\n",
    "\n",
    "            # Train Generator\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "            real_labels_for_gen = tf.ones((batch_size, 1))\n",
    "            g_loss_batch = gan.train_on_batch(noise, real_labels_for_gen)\n",
    "            if isinstance(g_loss_batch, list):  # if it returns a list, take the first element\n",
    "                g_loss_batch = g_loss_batch[0]\n",
    "            g_loss_epoch.append(g_loss_batch)\n",
    "\n",
    "            # Print progress for each step\n",
    "            print(f\"Step {step}/{total_steps_per_epoch} | \"\n",
    "                  f\"D Loss Real: {d_loss_real_batch:.4f}, \"\n",
    "                  f\"D Loss Fake: {d_loss_fake_batch:.4f}, \"\n",
    "                  f\"G Loss: {g_loss_batch:.4f}\", end=\"\\r\")\n",
    "\n",
    "        # Append average losses for each epoch\n",
    "        d_loss_real.append(np.mean(d_loss_real_epoch))\n",
    "        d_loss_fake.append(np.mean(d_loss_fake_epoch))\n",
    "        g_loss.append(np.mean(g_loss_epoch))\n",
    "\n",
    "        # Summary for each epoch\n",
    "        print(f\"\\nEpoch {epoch+1} Summary - D Loss Real: {d_loss_real[-1]:.4f}, \"\n",
    "              f\"D Loss Fake: {d_loss_fake[-1]:.4f}, G Loss: {g_loss[-1]:.4f}\")\n",
    "    \n",
    "    return d_loss_real, d_loss_fake, g_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "Step 1987/1987 | D Loss Real: 0.7524, D Loss Fake: 7.1664, G Loss: 0.0008\n",
      "Epoch 1 Summary - D Loss Real: 0.7397, D Loss Fake: 7.1141, G Loss: 0.0008\n",
      "\n",
      "Epoch 2/20\n",
      "Step 1987/1987 | D Loss Real: 0.7415, D Loss Fake: 7.2167, G Loss: 0.0007\n",
      "Epoch 2 Summary - D Loss Real: 0.7397, D Loss Fake: 7.1953, G Loss: 0.0008\n",
      "\n",
      "Epoch 3/20\n",
      "Step 1987/1987 | D Loss Real: 0.7296, D Loss Fake: 7.2365, G Loss: 0.0007\n",
      "Epoch 3 Summary - D Loss Real: 0.7397, D Loss Fake: 7.2264, G Loss: 0.0007\n",
      "\n",
      "Epoch 4/20\n",
      "Step 1987/1987 | D Loss Real: 0.7408, D Loss Fake: 7.2453, G Loss: 0.0007\n",
      "Epoch 4 Summary - D Loss Real: 0.7397, D Loss Fake: 7.2415, G Loss: 0.0007\n",
      "\n",
      "Epoch 5/20\n",
      "Step 1987/1987 | D Loss Real: 0.7323, D Loss Fake: 7.2481, G Loss: 0.0007\n",
      "Epoch 5 Summary - D Loss Real: 0.7397, D Loss Fake: 7.2469, G Loss: 0.0007\n",
      "\n",
      "Epoch 6/20\n",
      "Step 1987/1987 | D Loss Real: 0.7302, D Loss Fake: 7.2502, G Loss: 0.0007\n",
      "Epoch 6 Summary - D Loss Real: 0.7397, D Loss Fake: 7.2488, G Loss: 0.0007\n",
      "\n",
      "Epoch 7/20\n",
      "Step 1987/1987 | D Loss Real: 0.7396, D Loss Fake: 7.2514, G Loss: 0.0007\n",
      "Epoch 7 Summary - D Loss Real: 0.7397, D Loss Fake: 7.2505, G Loss: 0.0007\n",
      "\n",
      "Epoch 8/20\n",
      "Step 1/1987 | D Loss Real: 0.7396, D Loss Fake: 7.2515, G Loss: 0.0007\r"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Run the updated training function\n",
    "d_loss_real, d_loss_fake, g_loss = train_gan(gan, generator, discriminator, dataset, latent_dim, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_loss_real, label='Discriminator Real Loss')\n",
    "plt.plot(d_loss_fake, label='Discriminator Fake Loss')\n",
    "plt.plot(g_loss, label='Generator Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_faces(generator, latent_dim, n_samples=5):\n",
    "    noise = np.random.normal(0, 1, (n_samples, latent_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = (generated_images + 1) / 2  # Rescale to [0, 1]\n",
    "    return generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = generate_faces(generator, latent_dim)\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(len(generated_images)):\n",
    "    plt.subplot(1, len(generated_images), i+1)\n",
    "    plt.imshow(generated_images[i])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
