{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zyv2J43J9bxz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoKl-LLq9bx0"
      },
      "source": [
        "### Sigmoid \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RYNfZTWp9bx1"
      },
      "outputs": [],
      "source": [
        "## Quickly define the sigmoid function\n",
        "def sigmoid(x):\n",
        "    \"\"\"Sigmoid function\"\"\"\n",
        "    return 1.0 / (1.0 + np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "Mb2SHGIk9bx1",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "de90e26f-911f-427b-d056-2eba2ef4bb83"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "vals = np.linspace(-10, 10, num=100, dtype=np.float32)\n",
        "activation = sigmoid(vals)\n",
        "\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "fig = plt.figure(figsize=(12, 6))\n",
        "fig.suptitle('Sigmoid function')\n",
        "\n",
        "plt.plot(vals, activation)\n",
        "plt.grid(True, which='both')\n",
        "plt.axhline(y=0, color='k')\n",
        "plt.axvline(x=0, color='k')\n",
        "plt.yticks()\n",
        "plt.ylim([-0.5, 1.5])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WPNTFoI89bx2"
      },
      "outputs": [],
      "source": [
        "def logic_gate(w1, w2, b):\n",
        "    return lambda x1, x2: sigmoid(w1 * x1 + w2 * x2 + b)\n",
        "\n",
        "def test(gate):\n",
        "    for a, b in (0, 0), (0, 1), (1, 0), (1, 1):\n",
        "        print(\"{}, {}: {}\".format(a, b, np.round(gate(a, b))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kphjB5ZX9bx2",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "372f3645-7637-4c1d-cf89-9c600078ff3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0, 0: 0.0\n",
            "0, 1: 1.0\n",
            "1, 0: 1.0\n",
            "1, 1: 1.0\n"
          ]
        }
      ],
      "source": [
        "or_gate = logic_gate(20, 20, -10)\n",
        "test(or_gate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WogUlfL89bx3"
      },
      "source": [
        "## Student Exercise\n",
        "Try to figure out what values for the neurons would make this function as an AND gate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdYfYjp-9bx3",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "4c2c7175-9940-4ebc-917f-9349e1ff6f5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0, 0: 0.0\n",
            "0, 1: 0.0\n",
            "1, 0: 0.0\n",
            "1, 1: 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "w1 =10\n",
        "w2 =10\n",
        "b =-10\n",
        "and_gate = logic_gate(w1, w2, b)\n",
        "\n",
        "test(and_gate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0Jf2mgv9bx4"
      },
      "source": [
        "## Student Exercise\n",
        "Do the same for the NOR gate and the NAND gate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB6o6sJH9bx4"
      },
      "source": [
        "### NOR (Not Or) Gate\n",
        "\n",
        "<table>\n",
        "\n",
        "<tr>\n",
        "<th colspan=\"3\">NOR gate truth table</th>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<th colspan=\"2\">Input</th>\n",
        "<th>Output</th>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td>0</td>\n",
        "<td>0</td>\n",
        "<td>1</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td>0</td>\n",
        "<td>1</td>\n",
        "<td>0</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td>1</td>\n",
        "<td>0</td>\n",
        "<td>0</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td>1</td>\n",
        "<td>1</td>\n",
        "<td>0</td>\n",
        "</tr>\n",
        "\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTWgNGLf9bx4",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "32860ccd-4306-485f-893b-d2209bed64b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0, 0: 1.0\n",
            "0, 1: 0.0\n",
            "1, 0: 0.0\n",
            "1, 1: 0.0\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Fill in the w1, w2, and b parameters such that the truth table matches\n",
        "w1 =-10\n",
        "w2 =-10\n",
        "b =10\n",
        "nor_gate = logic_gate(w1, w2, b)\n",
        "\n",
        "test(nor_gate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKegVBkW9bx4"
      },
      "source": [
        "### NAND (Not And) Gate\n",
        "\n",
        "<table>\n",
        "\n",
        "<tr>\n",
        "<th colspan=\"3\">NAND gate truth table</th>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<th colspan=\"2\">Input</th>\n",
        "<th>Output</th>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td>0</td>\n",
        "<td>0</td>\n",
        "<td>1</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td>0</td>\n",
        "<td>1</td>\n",
        "<td>1</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td>1</td>\n",
        "<td>0</td>\n",
        "<td>1</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td>1</td>\n",
        "<td>1</td>\n",
        "<td>0</td>\n",
        "</tr>\n",
        "\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y02hapxl9bx5",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "bf1809ba-c593-4efd-f4da-ac031d23adf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0, 0: 1.0\n",
            "0, 1: 1.0\n",
            "1, 0: 1.0\n",
            "1, 1: 0.0\n"
          ]
        }
      ],
      "source": [
        "# TO DO: Fill in the w1, w2, and b parameters such that the truth table matches\n",
        "w1 =-10\n",
        "w2 =-10\n",
        "b =20\n",
        "nand_gate = logic_gate(w1, w2, b)\n",
        "\n",
        "test(nand_gate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htG6I9Yv9bx5"
      },
      "source": [
        "## Student Exercise: The limits of single neurons\n",
        "\n",
        "If you've taken computer science courses, you may know that the XOR gates are the basis of computation. They can be used as so-called \"half-adders\", the foundation of being able to add numbers together. Here's the truth table for XOR:\n",
        "\n",
        "### XOR (Exclusive Or) Gate\n",
        "\n",
        "<table>\n",
        "\n",
        "<tr>\n",
        "<th colspan=\"3\">XOR gate truth table</th>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<th colspan=\"2\">Input</th>\n",
        "<th>Output</th>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td>0</td>\n",
        "<td>0</td>\n",
        "<td>0</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td>0</td>\n",
        "<td>1</td>\n",
        "<td>1</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td>1</td>\n",
        "<td>0</td>\n",
        "<td>1</td>\n",
        "</tr>\n",
        "\n",
        "<tr>\n",
        "<td>1</td>\n",
        "<td>1</td>\n",
        "<td>0</td>\n",
        "</tr>\n",
        "\n",
        "</table>\n",
        "\n",
        "Now the question is, can you create a set of weights such that a single neuron can output this property?\n",
        "\n",
        "It turns out that you cannot. Single neurons can't correlate inputs, so it's just confused. So individual neurons are out. Can we still use neurons to somehow form an XOR gate?\n",
        "\n",
        "What if we tried something more complex:\n",
        "\n",
        "Here, we've got the inputs going to two separate gates: the top neuron is an OR gate, and the bottom is a NAND gate. The output of these gates then get passed to another neuron, which is an AND gate. If you work out the outputs at each combination of input values, you'll see that this is an XOR gate!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAx2Ueks9bx5",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "1b538143-81f1-421b-b917-9acc24527f32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0, 0: 1.0\n",
            "0, 1: 1.0\n",
            "1, 0: 1.0\n",
            "1, 1: 1.0\n"
          ]
        }
      ],
      "source": [
        "# Make sure you have or_gate, nand_gate, and and_gate working from above!\n",
        "def xor_gate(a, b):\n",
        "    c = or_gate(a, b)\n",
        "    d = nand_gate(a, b)\n",
        "    return and_gate(c, d)\n",
        "test(xor_gate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuEAz7L7wG9S"
      },
      "source": [
        "#Utilizing Multi Layered Perceptrons to simulate logic gates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3EbQwx8vguM",
        "outputId": "e353f247-a414-4fe0-a93f-b4ed1d8ec7e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 269ms/step - loss: 0.4565 - accuracy: 0.7500\n",
            "AND Gate - Loss: 0.4565, Accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "\n",
            "AND Gate - Predictions:\n",
            "   Input 1  Input 2  Actual Output  Predicted Output\n",
            "0        0        0              0               0.0\n",
            "1        0        1              0               0.0\n",
            "2        1        0              0               0.0\n",
            "3        1        1              1               0.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# AND gate data\n",
        "X_and = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_and = np.array([0, 0, 0, 1])\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import pandas as pd\n",
        "\n",
        "# Build the model\n",
        "model_and = Sequential([\n",
        "    Dense(4, activation='relu', input_dim=2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_and.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_and.fit(X_and, y_and, epochs=500, verbose=0)\n",
        "# Evaluate the model\n",
        "loss_and, accuracy_and = model_and.evaluate(X_and, y_and)\n",
        "print(f'AND Gate - Loss: {loss_and:.4f}, Accuracy: {accuracy_and:.4f}')\n",
        "\n",
        "# Make predictions\n",
        "\n",
        "\n",
        "predictions_and = model_and.predict(X_and)\n",
        "rounded_predictions_and = np.round(predictions_and)\n",
        "\n",
        "# Create a DataFrame for tabular display\n",
        "results_df = pd.DataFrame(X_and, columns=['Input 1', 'Input 2'])\n",
        "results_df['Actual Output'] = y_and\n",
        "results_df['Predicted Output'] = rounded_predictions_and.flatten()\n",
        "\n",
        "print(\"\\nAND Gate - Predictions:\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_jUe6CfxUBL",
        "outputId": "ad1fdab5-86a9-44e3-95de-e8bd8a5f6803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 159ms/step - loss: 0.2937 - accuracy: 0.7500\n",
            "OR Gate - Loss: 0.2937, Accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "\n",
            "OR Gate - Predictions:\n",
            "   Input 1  Input 2  Actual Output  Predicted Output\n",
            "0        0        0              0               1.0\n",
            "1        0        1              1               1.0\n",
            "2        1        0              1               1.0\n",
            "3        1        1              1               1.0\n"
          ]
        }
      ],
      "source": [
        "# OR gate data\n",
        "X_or = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_or = np.array([0, 1, 1, 1])\n",
        "\n",
        "# Build the model\n",
        "model_or = Sequential([\n",
        "    Dense(4, activation='relu', input_dim=2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_or.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_or.fit(X_or, y_or, epochs=1000, verbose=0)\n",
        "\n",
        "# Evaluate the model\n",
        "loss_or, accuracy_or = model_or.evaluate(X_or, y_or)\n",
        "print(f'OR Gate - Loss: {loss_or:.4f}, Accuracy: {accuracy_or:.4f}')\n",
        "\n",
        "# Make predictions\n",
        "predictions_or = model_or.predict(X_or)\n",
        "rounded_predictions_or = np.round(predictions_or)\n",
        "\n",
        "# Create a DataFrame for tabular display\n",
        "results_df_or = pd.DataFrame(X_or, columns=['Input 1', 'Input 2'])\n",
        "results_df_or['Actual Output'] = y_or\n",
        "results_df_or['Predicted Output'] = rounded_predictions_or.flatten()\n",
        "\n",
        "print(\"\\nOR Gate - Predictions:\")\n",
        "print(results_df_or)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VXToG4Ry7pu",
        "outputId": "dc2754ae-5584-4f76-8b58-1a578b3c1441"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 793ms/step - loss: 0.3629 - accuracy: 0.7500\n",
            "NAND Gate - Loss: 0.3629, Accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "\n",
            "NAND Gate - Predictions:\n",
            "   Input 1  Input 2  Actual Output  Predicted Output\n",
            "0        0        0              1               1.0\n",
            "1        0        1              1               1.0\n",
            "2        1        0              1               1.0\n",
            "3        1        1              0               1.0\n"
          ]
        }
      ],
      "source": [
        "# NAND gate data\n",
        "X_nand = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_nand = np.array([1, 1, 1, 0])\n",
        "\n",
        "# Build the model\n",
        "model_nand = Sequential([\n",
        "    Dense(4, activation='relu', input_dim=2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_nand.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_nand.fit(X_nand, y_nand, epochs=500, verbose=0)\n",
        "\n",
        "# Evaluate the model\n",
        "loss_nand, accuracy_nand = model_nand.evaluate(X_nand, y_nand)\n",
        "print(f'NAND Gate - Loss: {loss_nand:.4f}, Accuracy: {accuracy_nand:.4f}')\n",
        "\n",
        "# Make predictions\n",
        "predictions_nand = model_nand.predict(X_nand)\n",
        "rounded_predictions_nand = np.round(predictions_nand)\n",
        "\n",
        "# Create a DataFrame for tabular display\n",
        "results_df_nand = pd.DataFrame(X_nand, columns=['Input 1', 'Input 2'])\n",
        "results_df_nand['Actual Output'] = y_nand\n",
        "results_df_nand['Predicted Output'] = rounded_predictions_nand.flatten()\n",
        "\n",
        "print(\"\\nNAND Gate - Predictions:\")\n",
        "print(results_df_nand)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-UMtqN-y_I4",
        "outputId": "a96ec9e7-267e-4518-e2fb-a5a061ab231f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 213ms/step - loss: 0.4321 - accuracy: 0.7500\n",
            "XOR Gate - Loss: 0.4321, Accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "\n",
            "XOR Gate - Predictions:\n",
            "   Input 1  Input 2  Actual Output  Predicted Output\n",
            "0        0        0              0               0.0\n",
            "1        0        1              1               0.0\n",
            "2        1        0              1               1.0\n",
            "3        1        1              0               0.0\n"
          ]
        }
      ],
      "source": [
        "# XOR gate data\n",
        "X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_xor = np.array([0, 1, 1, 0])\n",
        "\n",
        "# Build the model\n",
        "model_xor = Sequential([\n",
        "    Dense(4, activation='relu', input_dim=2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_xor.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_xor.fit(X_xor, y_xor, epochs=1000, verbose=0)\n",
        "\n",
        "# Evaluate the model\n",
        "loss_xor, accuracy_xor = model_xor.evaluate(X_xor, y_xor)\n",
        "print(f'XOR Gate - Loss: {loss_xor:.4f}, Accuracy: {accuracy_xor:.4f}')\n",
        "\n",
        "# Make predictions\n",
        "predictions_xor = model_xor.predict(X_xor)\n",
        "rounded_predictions_xor = np.round(predictions_xor)\n",
        "\n",
        "# Create a DataFrame for tabular display\n",
        "results_df_xor = pd.DataFrame(X_xor, columns=['Input 1', 'Input 2'])\n",
        "results_df_xor['Actual Output'] = y_xor\n",
        "results_df_xor['Predicted Output'] = rounded_predictions_xor.flatten()\n",
        "\n",
        "print(\"\\nXOR Gate - Predictions:\")\n",
        "print(results_df_xor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXCuGA-kzIvl",
        "outputId": "585b17f5-553d-4c4b-9cdc-615041ae6cf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x000002841834EB00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.2312 - accuracy: 1.0000\n",
            "AND Gate - Loss: 0.2312, Accuracy: 1.0000\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002841834FD90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "\n",
            "AND Gate - Predictions:\n",
            "   Input 1  Input 2  Actual Output  Predicted Output\n",
            "0        0        0              0               0.0\n",
            "1        0        1              0               0.0\n",
            "2        1        0              0               0.0\n",
            "3        1        1              1               1.0\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x0000028435078160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.3768 - accuracy: 0.7500\n",
            "OR Gate - Loss: 0.3768, Accuracy: 0.7500\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028435079CF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "\n",
            "OR Gate - Predictions:\n",
            "   Input 1  Input 2  Actual Output  Predicted Output\n",
            "0        0        0              0               1.0\n",
            "1        0        1              1               1.0\n",
            "2        1        0              1               1.0\n",
            "3        1        1              1               1.0\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.3304 - accuracy: 0.7500\n",
            "NAND Gate - Loss: 0.3304, Accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "\n",
            "NAND Gate - Predictions:\n",
            "   Input 1  Input 2  Actual Output  Predicted Output\n",
            "0        0        0              1               1.0\n",
            "1        0        1              1               1.0\n",
            "2        1        0              1               1.0\n",
            "3        1        1              0               1.0\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.5258 - accuracy: 0.7500\n",
            "XOR Gate - Loss: 0.5258, Accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "\n",
            "XOR Gate - Predictions:\n",
            "   Input 1  Input 2  Actual Output  Predicted Output\n",
            "0        0        0              0               0.0\n",
            "1        0        1              1               1.0\n",
            "2        1        0              1               0.0\n",
            "3        1        1              0               0.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Function to build, train, and evaluate a model for a logic gate\n",
        "def train_logic_gate(X, y, gate_name):\n",
        "    model = Sequential([\n",
        "        Dense(4, activation='relu', input_dim=2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X, y, epochs=1000, verbose=0)\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, accuracy = model.evaluate(X, y)\n",
        "    print(f'{gate_name} Gate - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(X)\n",
        "    rounded_predictions = np.round(predictions)\n",
        "\n",
        "    # Create a DataFrame for tabular display\n",
        "    results_df = pd.DataFrame(X, columns=['Input 1', 'Input 2'])\n",
        "    results_df['Actual Output'] = y\n",
        "    results_df['Predicted Output'] = rounded_predictions.flatten()\n",
        "\n",
        "    print(f\"\\n{gate_name} Gate - Predictions:\")\n",
        "    print(results_df)\n",
        "\n",
        "# AND gate data\n",
        "X_and = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_and = np.array([0, 0, 0, 1])\n",
        "train_logic_gate(X_and, y_and, \"AND\")\n",
        "\n",
        "# OR gate data\n",
        "X_or = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_or = np.array([0, 1, 1, 1])\n",
        "train_logic_gate(X_or, y_or, \"OR\")\n",
        "\n",
        "# NAND gate data\n",
        "X_nand = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_nand = np.array([1, 1, 1, 0])\n",
        "train_logic_gate(X_nand, y_nand, \"NAND\")\n",
        "\n",
        "# XOR gate data\n",
        "X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_xor = np.array([0, 1, 1, 0])\n",
        "train_logic_gate(X_xor, y_xor, \"XOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7FpiMqf9bx5"
      },
      "source": [
        "## Feedforward Networks as Matrix Computations\n",
        "\n",
        "We discussed previously how the feed-forward computation of a neural network can be thought of as matrix calculations and activation functions.  We will do some actual computations with matrices to see this in action.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUoDzs7a9bx5"
      },
      "source": [
        "## Exercise\n",
        "Provided below are the following:\n",
        "\n",
        "- Three weight matrices `W_1`, `W_2` and `W_3` representing the weights in each layer.  The convention for these matrices is that each $W_{i,j}$ gives the weight from neuron $i$ in the previous (left) layer to neuron $j$ in the next (right) layer.  \n",
        "- A vector `x_in` representing a single input and a matrix `x_mat_in` representing 7 different inputs.\n",
        "- Two functions: `soft_max_vec` and `soft_max_mat` which apply the soft_max function to a single vector, and row-wise to a matrix.\n",
        "\n",
        "The goals for this exercise are:\n",
        "1. For input `x_in` calculate the inputs and outputs to each layer (assuming sigmoid activations for the middle two layers and soft_max output for the final layer.\n",
        "2. Write a function that does the entire neural network calculation for a single input\n",
        "3. Write a function that does the entire neural network calculation for a matrix of inputs, where each row is a single input.\n",
        "4. Test your functions on `x_in` and `x_mat_in`.\n",
        "\n",
        "This illustrates what happens in a NN during one single forward pass. Roughly speaking, after this forward pass, it remains to compare the output of the network to the known truth values, compute the gradient of the loss function and adjust the weight matrices `W_1`, `W_2` and `W_3` accordingly, and iterate. Hopefully this process will result in better weight matrices and our loss will be smaller afterwards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY3waQyz9bx6",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "1b9a3357-72cc-44cf-b15a-dc46974604f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the matrix W_1\n",
            "\n",
            "[[ 2 -1  1  4]\n",
            " [-1  2 -3  1]\n",
            " [ 3 -2 -1  5]]\n",
            "------------------------------\n",
            "vector input x_in\n",
            "\n",
            "[0.5 0.8 0.2]\n",
            "------------------------------\n",
            "matrix input x_mat_in -- starts with the vector `x_in`\n",
            "\n",
            "[[0.5 0.8 0.2]\n",
            " [0.1 0.9 0.6]\n",
            " [0.2 0.2 0.3]\n",
            " [0.6 0.1 0.9]\n",
            " [0.5 0.5 0.4]\n",
            " [0.9 0.1 0.9]\n",
            " [0.1 0.8 0.7]]\n"
          ]
        }
      ],
      "source": [
        "W_1 = np.array([[2,-1,1,4],[-1,2,-3,1],[3,-2,-1,5]])\n",
        "W_2 = np.array([[3,1,-2,1],[-2,4,1,-4],[-1,-3,2,-5],[3,1,1,1]])\n",
        "W_3 = np.array([[-1,3,-2],[1,-1,-3],[3,-2,2],[1,2,1]])\n",
        "x_in = np.array([.5,.8,.2])\n",
        "x_mat_in = np.array([[.5,.8,.2],[.1,.9,.6],[.2,.2,.3],[.6,.1,.9],[.5,.5,.4],[.9,.1,.9],[.1,.8,.7]])\n",
        "\n",
        "def soft_max_vec(vec):\n",
        "    return np.exp(vec)/(np.sum(np.exp(vec)))\n",
        "\n",
        "def soft_max_mat(mat):\n",
        "    return np.exp(mat)/(np.sum(np.exp(mat),axis=1).reshape(-1,1))\n",
        "\n",
        "print('the matrix W_1\\n')\n",
        "print(W_1)\n",
        "print('-'*30)\n",
        "print('vector input x_in\\n')\n",
        "print(x_in)\n",
        "print ('-'*30)\n",
        "print('matrix input x_mat_in -- starts with the vector `x_in`\\n')\n",
        "print(x_mat_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U5tL5N59bx6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsYwTWuC9bx6"
      },
      "outputs": [],
      "source": [
        "## Student to do the calculations below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkiV-5tP9bx6",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "579f1339-7b7f-4bed-f90a-e16b68704228"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.8,  0.7, -2.1,  3.8])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z_2 = np.dot(x_in,W_1)\n",
        "z_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0Wxrp589bx6",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "ceee3aa5-e394-4b33-9f6a-65a956a01ee6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.68997448, 0.66818777, 0.10909682, 0.97811873])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a_2 = sigmoid(z_2)\n",
        "a_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIGaCB1S9bx7",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "3df2b1a3-63e3-45d9-99ab-842ce3411146"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 3.55880727,  4.01355384,  0.48455118, -1.55014198])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z_3 = np.dot(a_2,W_2)\n",
        "z_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q8wghRh9bx7",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "202530a9-b8f1-43a3-abcf-75cfd0cd6f4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.97231549, 0.98225163, 0.61882199, 0.17506576])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a_3 = sigmoid(z_3)\n",
        "a_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxB0KraT9bx7",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "e1928cee-5698-4588-ee99-f59e879075bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 2.04146788,  1.04718238, -3.47867612])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z_4 = np.dot(a_3,W_3)\n",
        "z_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Bu38nK7A9bx7"
      },
      "outputs": [],
      "source": [
        "def soft_max_vec(vec):\n",
        "    return np.exp(vec)/(np.sum(np.exp(vec)))\n",
        "\n",
        "def soft_max_mat(mat):\n",
        "    return np.exp(mat)/(np.sum(np.exp(mat),axis=1).reshape(-1,1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ-BMkrM9bx7",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "b7c02170-51ec-41c0-d118-c2ec27a74141"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.72780576, 0.26927918, 0.00291506])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_out = soft_max_vec(z_4)\n",
        "y_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JYXOZIrJ9bx8"
      },
      "outputs": [],
      "source": [
        "## A one-line function to do the entire neural net computation\n",
        "\n",
        "def nn_comp_vec(x):\n",
        "    return soft_max_vec(sigmoid(sigmoid(np.dot(x,W_1)).dot(W_2)).dot(W_3))\n",
        "\n",
        "def nn_comp_mat(x):\n",
        "    return soft_max_mat(sigmoid(sigmoid(np.dot(x,W_1)).dot(W_2)).dot(W_3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lejCwxRQ9bx8",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "60e7c89d-e5b7-4535-af91-7d2575a10fa2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.72780576, 0.26927918, 0.00291506])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn_comp_vec(x_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7n4meubn9bx8",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "42880f9e-843f-4cff-e2f5-38f19a86953d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.72780576, 0.26927918, 0.00291506],\n",
              "       [0.62054212, 0.37682531, 0.00263257],\n",
              "       [0.69267581, 0.30361576, 0.00370844],\n",
              "       [0.36618794, 0.63016955, 0.00364252],\n",
              "       [0.57199769, 0.4251982 , 0.00280411],\n",
              "       [0.38373781, 0.61163804, 0.00462415],\n",
              "       [0.52510443, 0.4725011 , 0.00239447]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn_comp_mat(x_mat_in)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
